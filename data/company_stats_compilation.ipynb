{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2171de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12b204",
   "metadata": {},
   "source": [
    "## Load and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c2af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soomi/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py:304: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "file_path = './filtered_columns_data/'\n",
    "\n",
    "raw_data2016 = pd.read_csv(file_path + 'LCA_FY2016.csv')\n",
    "raw_data2016 = raw_data2016.rename({'CASE_SUBMITTED': 'RECEIVED_DATE', 'SOC_NAME': 'SOC_TITLE'}, axis=1)\n",
    "\n",
    "raw_data2017 = pd.read_csv(file_path + 'LCA_FY2017.csv')\n",
    "raw_data2017 = raw_data2017.rename({'CASE_SUBMITTED': 'RECEIVED_DATE', 'SOC_NAME': 'SOC_TITLE'}, axis=1)\n",
    "\n",
    "raw_data2018 = pd.read_csv(file_path + 'LCA_FY2018.csv')\n",
    "raw_data2018 = raw_data2018.rename({'CASE_SUBMITTED': 'RECEIVED_DATE', 'SOC_NAME': 'SOC_TITLE'}, axis=1)\n",
    "\n",
    "raw_data2020 = pd.concat(\n",
    "    map(pd.read_csv, [(file_path+'LCA_FY2020_Q1.csv'), (file_path+'LCA_FY2020_Q2.csv'), \n",
    "                      (file_path+'LCA_FY2020_Q3.csv'), (file_path+'LCA_FY2020_Q4.csv')]), ignore_index=True)\n",
    "\n",
    "raw_data2021 = pd.concat(\n",
    "    map(pd.read_csv, [(file_path+'LCA_FY2021_Q1.csv'), (file_path+'LCA_FY2021_Q2.csv'), \n",
    "                      (file_path+'LCA_FY2021_Q3.csv'), (file_path+'LCA_FY2021_Q4.csv')]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d2f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job occupation codes and corresponding names\n",
    "big_group_dict = {\n",
    "    11: 'Management Occupations',\n",
    "    13: 'Business and Financial Operations Occupations',\n",
    "    15: 'Computer and Mathematical Occupations',\n",
    "    17: 'Architecture and Engineering Occupations',\n",
    "    19: 'Life, Physical, and Social Science Occupations',\n",
    "    21: 'Community and Social Service Occupations',\n",
    "    23: 'Legal Occupations',\n",
    "    25: 'Educational Instruction and Library Occupations',\n",
    "    27: 'Arts, Design, Entertainment, Sports, and Media Occupations',\n",
    "    29: 'Healthcare Practitioners and Technical Occupations',\n",
    "    31: 'Healthcare Support Occupations',\n",
    "    33: 'Protective Service Occupations',\n",
    "    35: 'Food Preparation and Serving Related Occupations',\n",
    "    37: 'Building and Grounds Cleaning and Maintenance Occupations',\n",
    "    39: 'Personal Care and Service Occupations',\n",
    "    41: 'Sales and Related Occupations',\n",
    "    43: 'Office and Administrative Support Occupations',\n",
    "    45: 'Farming, Fishing, and Forestry Occupations',\n",
    "    47: 'Construction and Extraction Occupations',\n",
    "    49: 'Installation, Maintenance, and Repair Occupations',\n",
    "    51: 'Production Occupations',\n",
    "    53: 'Transportation and Material Moving Occupations',\n",
    "    55: 'Military Specific Occupations'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd2841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process loaded data\n",
    "def get_data(data):\n",
    "    \n",
    "    data = data.rename({'CASE_SUBMITTED': 'RECEIVED_DATE', 'SOC_NAME': 'SOC_TITLE'}, axis=1)\n",
    "    \n",
    "    # Deal with erroneous data in SOC_CODE\n",
    "    data = data[data['SOC_CODE'].notna()]\n",
    "    data = data.replace({np.nan: None})\n",
    "    data = data[~data['SOC_CODE'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
    "    data = data[data['SOC_CODE'].apply(lambda x: len(x.split('-')[0])>1)]\n",
    "    \n",
    "    # Big group define\n",
    "    data['BIG_GROUP_CODE'] = [int(str(i)[0:2]) for i in data.SOC_CODE]\n",
    "    data = data[data['BIG_GROUP_CODE'].isin(big_group_dict.keys())] # drop rows with weird SOC codes\n",
    "    data['BIG_GROUP_NAME'] = [big_group_dict[i] for i in data.BIG_GROUP_CODE]\n",
    "    \n",
    "    data['WAGE_RATE_OF_PAY_FROM'] = [convert_wage_str(i) for i in data.WAGE_RATE_OF_PAY_FROM]\n",
    "    data['WAGE_RATE_OF_PAY_TO'] = [convert_wage_str(i) for i in data.WAGE_RATE_OF_PAY_TO]\n",
    "    \n",
    "    data = data.replace({np.nan: None})\n",
    "    \n",
    "    # Calculate average wage\n",
    "    tmp = []\n",
    "    for idx, row in data.iterrows():\n",
    "        if (row.WAGE_RATE_OF_PAY_TO) is None:\n",
    "            tmp.append(row.WAGE_RATE_OF_PAY_FROM)\n",
    "        else:\n",
    "            tmp.append((row.WAGE_RATE_OF_PAY_FROM + row.WAGE_RATE_OF_PAY_TO) / 2)\n",
    "            \n",
    "    data['AVERAGE_WAGE'] = tmp\n",
    "    \n",
    "    # Uppercase CASE_STATUS & EMPLOYER_NAME\n",
    "    data['CASE_STATUS'] = data['CASE_STATUS'].str.upper()\n",
    "    data['EMPLOYER_NAME'] = data['EMPLOYER_NAME'].str.upper()\n",
    "    \n",
    "    # Convert datetime\n",
    "    data.RECEIVED_DATE = pd.to_datetime(data.RECEIVED_DATE)\n",
    "    data.DECISION_DATE = pd.to_datetime(data.DECISION_DATE)\n",
    "    data.ORIGINAL_CERT_DATE = pd.to_datetime(data.ORIGINAL_CERT_DATE)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def convert_wage_str(wage_str):\n",
    "    if wage_str is None:\n",
    "        return None\n",
    "    \n",
    "    # Delete the dollar sign\n",
    "    wage_str = wage_str[1:]\n",
    "    \n",
    "    wage_str = wage_str.replace(',', '')\n",
    "    return float(wage_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ac21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process data for each year\n",
    "data2016 = get_data(raw_data2016)\n",
    "data2017 = get_data(raw_data2017)\n",
    "data2018 = get_data(raw_data2018)\n",
    "data2020 = get_data(raw_data2020)\n",
    "data2021 = get_data(raw_data2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4e3a3",
   "metadata": {},
   "source": [
    "## Filter data by company and visualize relevant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c787818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data of the particular company only\n",
    "def filter_data_by_company_name(data, company_name):\n",
    "    return data[(data.EMPLOYER_NAME.str.contains(company_name)) & (data.VISA_CLASS == 'H-1B')]\n",
    "\n",
    "def get_company_data(company_name):\n",
    "\n",
    "    company_data_2016 = filter_data_by_company_name(data2016, company_name)\n",
    "    company_data_2017 = filter_data_by_company_name(data2017, company_name)\n",
    "    company_data_2018 = filter_data_by_company_name(data2018, company_name)\n",
    "    company_data_2020 = filter_data_by_company_name(data2020, company_name)\n",
    "    company_data_2021 = filter_data_by_company_name(data2021, company_name)\n",
    "    \n",
    "    # Compile the data over the years\n",
    "    data = {\n",
    "        2016: company_data_2016,\n",
    "        2017: company_data_2017,\n",
    "        2018: company_data_2018,\n",
    "        2020: company_data_2020,\n",
    "        2021: company_data_2021\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4abbdd",
   "metadata": {},
   "source": [
    "### Visualize the approval rate and waiting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad97b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approval_number(data):\n",
    "    return len(data[data.CASE_STATUS == 'CERTIFIED']) + len(data[data.CASE_STATUS == 'CERTIFIED-WITHDRAWN'])\n",
    "\n",
    "def approval_rate(data):\n",
    "    return approval_number(data) / len(data)\n",
    "\n",
    "def denial_number(data):\n",
    "    return len(data[data.CASE_STATUS == 'DENIED'])\n",
    "\n",
    "def calculate_approval_rate_over_years(data):\n",
    "    approval_rate_over_years = []\n",
    "    years = []\n",
    "    for year, data_year in data.items():\n",
    "        approval_rate_res = approval_rate(data_year)\n",
    "        years.append(year)\n",
    "        approval_rate_over_years.append(approval_rate_res)\n",
    "    return approval_rate_over_years, years\n",
    "\n",
    "def plot_approval_rate_over_years(data):\n",
    "    approval_rate_over_years, years = calculate_approval_rate_over_years(data)\n",
    "    plt.plot(years, approval_rate_over_years)\n",
    "    plt.title('Approval rate over years')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_waiting_time(data):\n",
    "    result = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row.CASE_STATUS == 'CERTIFIED-WITHDRAWN':\n",
    "            result.append((row.ORIGINAL_CERT_DATE - row.RECEIVED_DATE).days)\n",
    "        elif row.CASE_STATUS == 'CERTIFIED':\n",
    "            result.append((row.DECISION_DATE - row.RECEIVED_DATE).days)\n",
    "    return np.mean(result)\n",
    "\n",
    "def plot_waiting_time(data):\n",
    "    result, years = [], []\n",
    "    for year, data_year in data.items():\n",
    "        years.append(year)\n",
    "        result.append(calculate_waiting_time(data_year))\n",
    "    plt.plot(years, result)\n",
    "    plt.title('Waiting time over years')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9684ab",
   "metadata": {},
   "source": [
    "### Visualize the number of applications per job industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334a6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_different_groups_applications_number(data, big_group_dict):\n",
    "    # Find all uniques groups inside the data\n",
    "    unique_groups = set(company_data_2021.BIG_GROUP_CODE)\n",
    "    # Results\n",
    "    applications_count = []\n",
    "    \n",
    "    # For each group, count how many applications\n",
    "    for group_code in unique_groups:\n",
    "        count = count_applications_on_CODE(group_code, data)\n",
    "        applications_count.append(count)\n",
    "        \n",
    "    # Present the results\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    groups = [big_group_dict[i] for i in unique_groups] \n",
    "    ax.barh(groups, applications_count)\n",
    "    for i, v in enumerate(applications_count):\n",
    "        ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')\n",
    "\n",
    "    plt.title(\"Number of applications per job industry\")\n",
    "    plt.show()\n",
    "    \n",
    "def count_applications_on_CODE(group_code, data):\n",
    "    return sum(data.BIG_GROUP_CODE == group_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be396f54",
   "metadata": {},
   "source": [
    "### Visualize the wage data per job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6ad28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jobs_on_group(group_code, data):\n",
    "    # Filter all applications with the same group code\n",
    "    data = data.loc[data.BIG_GROUP_CODE == group_code]\n",
    "    \n",
    "    # Find all uniques job_code\n",
    "    unique_job_titles = set(data.SOC_TITLE)\n",
    "    \n",
    "    # Get the job title based on job_code - later, if necessary\n",
    "   \n",
    "    # Calculate salary stats for each job code\n",
    "    average_on_job = []\n",
    "    jobs = []\n",
    "    for job_title in unique_job_titles:\n",
    "        jobs.append(job_title)\n",
    "        average_on_job.append(calculate_salary_stats(job_title, data))\n",
    "    # Plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.barh(jobs, average_on_job)\n",
    "    for i, v in enumerate(average_on_job):\n",
    "        ax.text(v + 3, i - .1 , str(v), color='blue', fontweight='bold')\n",
    "\n",
    "    plt.title(\"Average wage based on job\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def calculate_salary_stats(job_title, data):\n",
    "    # Find all applications of specific job code\n",
    "    new_data = data.loc[data.SOC_TITLE == job_title]\n",
    "    # Collect all salaries\n",
    "    salaries = new_data.AVERAGE_WAGE\n",
    "    \n",
    "    # Mean\n",
    "    mean_salaries = np.round(np.mean(salaries))\n",
    "    \n",
    "    # Median\n",
    "    median_salaries = np.round(np.median(salaries))\n",
    "    \n",
    "    # Min, Max\n",
    "    min_salaries = min(salaries)\n",
    "    max_salaries = max(salaries)\n",
    "    \n",
    "    # 95 Confidence Interval\n",
    "    \n",
    "    return mean_salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37544cd",
   "metadata": {},
   "source": [
    "## Find companies that have consistent names throughout the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157a45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the unique company names per data\n",
    "def unique_companies(data):\n",
    "    data['EMPLOYER_NAME'] = data['EMPLOYER_NAME'].str.upper()\n",
    "    return data['EMPLOYER_NAME'].unique()\n",
    "\n",
    "companies_2016 = unique_companies(raw_data2016)\n",
    "companies_2017 = unique_companies(raw_data2017)\n",
    "companies_2018 = unique_companies(raw_data2018)\n",
    "companies_2020 = unique_companies(raw_data2020)\n",
    "companies_2021 = unique_companies(raw_data2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859b4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27160 companies have the same name in 2020 and 2021\n",
      "14712 companies have the same name in 2018 and 2020\n",
      "11441 companies have the same name in 2017 and 2018\n",
      "9183 companies have the same name in 2016 and 2017\n"
     ]
    }
   ],
   "source": [
    "# find companies with overlapping names over the years\n",
    "overlap_2020_2021 = []\n",
    "for company in companies_2021:\n",
    "    if company in companies_2020:\n",
    "        overlap_2020_2021.append(company)\n",
    "print(f\"{len(overlap_2020_2021)} companies have the same name in 2020 and 2021\")\n",
    "\n",
    "overlap_2018_2020 = []\n",
    "for company in overlap_2020_2021:\n",
    "    if company in companies_2018:\n",
    "        overlap_2018_2020.append(company)\n",
    "print(f\"{len(overlap_2018_2020)} companies have the same name in 2018 and 2020\")\n",
    "\n",
    "overlap_2017_2018 = []\n",
    "for company in overlap_2018_2020:\n",
    "    if company in companies_2017:\n",
    "        overlap_2017_2018.append(company)\n",
    "print(f\"{len(overlap_2017_2018)} companies have the same name in 2017 and 2018\")\n",
    "\n",
    "overlap_2016_2017 = []\n",
    "for company in overlap_2017_2018:\n",
    "    if company in companies_2016:\n",
    "        overlap_2016_2017.append(company)\n",
    "print(f\"{len(overlap_2016_2017)} companies have the same name in 2016 and 2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49b5527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RETAIL SERVICES AND SYSTEMS, INC. (DBA TOTAL WINE'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping_companies = overlap_2016_2017\n",
    "overlapping_companies.pop(3647) # remove erroneous entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3b379",
   "metadata": {},
   "source": [
    "## Retrieve search filter data for each company (only using 2021 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b180dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_per_company(company_name):\n",
    "    data = filter_data_by_company_name(data2021, company_name)\n",
    "    columns = ['EMPLOYER_CITY', 'EMPLOYER_STATE', 'BIG_GROUP_NAME', 'FULL_TIME_POSITION']\n",
    "    result = {}\n",
    "    for col in columns:\n",
    "        result[col] = get_unique_values(data, col)\n",
    "    job_industry_list = result['BIG_GROUP_NAME']\n",
    "    result['JOB_INDUSTRY_WAGE'] = create_job_industry_and_wage(data, job_industry_list)\n",
    "    result['EMPLOYER_CITY'] = validate_city(result['EMPLOYER_CITY'], result['EMPLOYER_STATE'])\n",
    "    result['FULL_TIME_POSITION'] = convert_FT_PT(result['FULL_TIME_POSITION'])\n",
    "    result['COMPANY_NAME'] = company_name\n",
    "    result['APPROVAL_RATE'] = create_job_industry_and_approval_rate(data, job_industry_list)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_unique_values(data, column):\n",
    "    return list(np.unique(data[column].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabe582",
   "metadata": {},
   "source": [
    "### Validate city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06477051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the validity of the city names in the dataset\n",
    "# Ignore data entries with erroneous city names (ex. typos)\n",
    "def create_cities_on_states():\n",
    "    states_cities_df = pd.read_csv('./us_cities_states_counties.csv', delimiter='|', on_bad_lines='skip')\n",
    "    cities_on_states = {}\n",
    "    for index, row in states_cities_df.iterrows():\n",
    "        city = row[0]\n",
    "        state = row[1]\n",
    "        if state not in cities_on_states:\n",
    "            cities_on_states[state] = set()\n",
    "        cities_on_states[state].add(city)\n",
    "    return cities_on_states\n",
    "\n",
    "cities_on_states = create_cities_on_states()\n",
    "\n",
    "def get_legit_cities(cities_on_states, state_list):\n",
    "    res = []\n",
    "    for state in state_list:\n",
    "        res += (cities_on_states[state])\n",
    "    return res\n",
    "\n",
    "def validate_city(city_list, state_list):\n",
    "    # get a list of the legit cities\n",
    "    legit_cities = set(get_legit_cities(cities_on_states, state_list))\n",
    "    \n",
    "    # make every city name in the same format (first letters are capitalized)\n",
    "    # and get unique city values\n",
    "    check_cities = set([city.title() for city in city_list])\n",
    "    \n",
    "    # check whether the city in dataset is valid by finding matches\n",
    "    valid_cities = check_cities.intersection(legit_cities)\n",
    "    \n",
    "    # return a list of cities that are in valid form\n",
    "    return list(valid_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de838f2d",
   "metadata": {},
   "source": [
    "### Calculate the average and range of salary per job industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0367b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wage_per_job_industry(data, job_industry_name):\n",
    "    \n",
    "    # ignore entries with hourly wages\n",
    "    data = data[(data['WAGE_UNIT_OF_PAY']=='Year') & (data['BIG_GROUP_NAME']==job_industry_name)]\n",
    "    \n",
    "    if len(data)==0:\n",
    "        return 0\n",
    "    \n",
    "    # get the minimum & mean & maximum of AVERAGE_WAGE\n",
    "    salaries = data.AVERAGE_WAGE\n",
    "    \n",
    "    # Mean\n",
    "    mean_salaries = np.round(np.mean(salaries))\n",
    "    \n",
    "    # Min, Max\n",
    "    min_salaries = min(salaries)\n",
    "    max_salaries = max(salaries)\n",
    "    \n",
    "    return [mean_salaries, min_salaries, max_salaries]\n",
    "\n",
    "def create_job_industry_and_wage(data, job_industry_list):\n",
    "    result = {}\n",
    "    for job_industry in job_industry_list:\n",
    "        result[job_industry] = calculate_wage_per_job_industry(data, job_industry)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f423937",
   "metadata": {},
   "source": [
    "### Calculate the 2021 application approval rate per job industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980c52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_approval_rate_per_job_industry(data, job_industry_name):\n",
    "    \n",
    "    data = data[(data['BIG_GROUP_NAME']==job_industry_name)]\n",
    "    \n",
    "    return approval_rate(data)\n",
    "\n",
    "def create_job_industry_and_approval_rate(data, job_industry_list):\n",
    "    result = {}\n",
    "    for job_industry in job_industry_list:\n",
    "        result[job_industry] = calculate_approval_rate_per_job_industry(data, job_industry)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470a352",
   "metadata": {},
   "source": [
    "### Convert Full-Time vs Part-Time entries into relevant formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d3a3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Y, N] => [\"Full-time, Part-time]\n",
    "def convert_FT_PT(FT_PT_data):\n",
    "    for i in range(len(FT_PT_data)):\n",
    "        if FT_PT_data[i] == \"Y\":\n",
    "            FT_PT_data[i] = \"Full-time\"\n",
    "        else:\n",
    "            FT_PT_data[i] = \"Part-time\"\n",
    "            \n",
    "    return FT_PT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b009101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soomi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2x/s8v6w0dj1jjfhbtnwc4tkt840000gn/T/ipykernel_95538/124571579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moverlapping_companies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stats_per_company\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcompany_name_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COMPANY_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2x/s8v6w0dj1jjfhbtnwc4tkt840000gn/T/ipykernel_95538/4015395731.py\u001b[0m in \u001b[0;36mget_stats_per_company\u001b[0;34m(company_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mjob_industry_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BIG_GROUP_NAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'JOB_INDUSTRY_WAGE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_job_industry_and_wage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_industry_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2x/s8v6w0dj1jjfhbtnwc4tkt840000gn/T/ipykernel_95538/4015395731.py\u001b[0m in \u001b[0;36mget_unique_values\u001b[0;34m(data, column)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_unique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "company_name_list = []\n",
    "city_list = []\n",
    "state_list = []\n",
    "job_industry_list = []\n",
    "full_time_list = []\n",
    "approval_rate_list = []\n",
    "\n",
    "for company in overlapping_companies:\n",
    "    result = get_stats_per_company(company)\n",
    "    \n",
    "    company_name_list.append(result['COMPANY_NAME'])\n",
    "    city_list.append(result['EMPLOYER_CITY'])\n",
    "    state_list.append(result['EMPLOYER_STATE'])\n",
    "    job_industry_list.append(result['JOB_INDUSTRY_WAGE'])\n",
    "    full_time_list.append(result['FULL_TIME_POSITION'])\n",
    "    approval_rate_list.append(result['APPROVAL_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'Company_Name': company_name_list, 'City': city_list, 'State': state_list, \n",
    "                   'Job_Industry': job_industry_list, 'Full_Time': full_time_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bda958",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('company_search_filters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea9a5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('company_search_filters.csv')\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
